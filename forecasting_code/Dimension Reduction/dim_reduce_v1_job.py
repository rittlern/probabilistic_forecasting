import numpy as np

# training parameters; supply a single value if you want value fixed throughout training, or a list if dynamic
num_training_phases = 1  # each training phrase can come with it's own parameter settings

training_params = {

    # core training parameters
    'm': 2,  # final dimensional target for predictors
    'gaussian_assumption': False,  # assume the data are generated by a joint Gaussian in the training?
    'num_steps': 500,  # steps in each phase in the training
    'batch_size': 600,  # mini-batch size
    'num_batches_to_accum': 5,  # number of gradients to sample/accumulate before updating parameters
    'learning_rate': 1e-2,  # learning rate for each phase in the training
    'synthetic_data': False,  # is the data synthetic? used only for read/save directory, formatting, etc.

    # secondary training parameters
    'unique': False,  # learn a unique transformation?
    'opt_init': False,  # initialize the learning in part using the optimal transformation from normal theory
    'true_cov': False,  # if synthetic, supply the true covariance to isolate training, rule out cov est in diagnosing
    'estimate_var_baseline': True,  # estimate the optimal var under gaussian assumption; no need when using synthetic
    'normalize': True,  # normalize batches. set to
    'max_batch': False,  # if True, take all of the training data in each batch, regardless of batch_size setting
    'alpha': 0,  # regularization penalty parameter; 0 means no regularization
    'norm': 2,  # regularization penalty type. see arguments for np.linalg.norm
    'training_seed': 10,  # seed used for initialization and mini-batching
    'beta_1': .999,  # Adam parameters; use of large beta_1 for knn (~.999) is recommended
    'beta_2': .9999,  # Adam parameters
    'training_phases': list(range(num_training_phases)),  # phases of the training

    # parameters for non-parameteric estimation of densities
    'est_type': 'knn',  # type of nonparametric estimation to use; options are 'knn','kde' and 'kde_gen'
    'k_yz': 80,  # how many nearest neighbors to use in density estimation of (y,z) = (y,Tx)
    'k_z': 100,  # how many nearest neighbors to use in density estimation of z = Tx
    'h': 2,  # smoothing parameters for kde. should be a numpy array of length m+p or a float_dim)
    'A': None,  # cov mat for gaussian kernel used in kde, up to constant multiple. should be (m+p) x (m+p)

    # settings for resumption of training/ training on old data
    'resume_model': None,  # model of form 'T100.npy' to resume training on
    'resume_model_dir': None,  # directory in which model lives'Experiments/run_201/'
    'data_directory': None,  # a subdir of Experiments or Real_Experiments where some interesting data live

}

